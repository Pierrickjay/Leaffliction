{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 14:20:53.834562: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-06 14:20:53.836621: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-06 14:20:53.857999: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-06 14:20:53.858020: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-06 14:20:53.858683: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-06 14:20:53.862268: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-06 14:20:53.862649: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-06 14:20:55.250256: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance\n",
    "from plantcv import plantcv as pcv\n",
    "from plantcv.parallel import WorkflowInputs\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import experimental, Conv2D, MaxPooling2D, Dense, Flatten\n",
    "import os\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(path, img_size, batch_size):\n",
    "    return tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        path,\n",
    "        shuffle=True,\n",
    "        image_size=(img_size, img_size)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeBack(img, size_fill, enhance_val, buffer_size):\n",
    "    img_img = Image.fromarray(img, mode=\"RGB\")\n",
    "    contr_img = ImageEnhance.Contrast(img_img).enhance(enhance_val)\n",
    "    gray_img = pcv.rgb2gray_lab(rgb_img=np.array(contr_img), channel='a')\n",
    "    thresh = pcv.threshold.triangle(\n",
    "        gray_img=gray_img, object_type=\"dark\", xstep=100)\n",
    "    edge_ok = pcv.fill(bin_img=thresh, size=5000)\n",
    "    mask = pcv.fill(bin_img=pcv.invert(gray_img=edge_ok), size=size_fill)\n",
    "    contours, _ = cv2.findContours(\n",
    "        mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask_buf = mask.copy()\n",
    "    if (len(contours)):\n",
    "        cv2.drawContours(mask_buf,\n",
    "                         contours[np.argmax([len(c) for c in contours])],\n",
    "                         -1, (0, 0, 0), buffer_size)\n",
    "    if ([mask_buf[0, 0], mask_buf[0, -1],\n",
    "         mask_buf[0, -1], mask_buf[-1, 0]] == [0, 0, 0, 0]):\n",
    "        mask_buf[0:11, 0:11] = 255\n",
    "        mask_buf[-11:, -11:] = 255\n",
    "        mask_buf[0:11, -11:] = 255\n",
    "        mask_buf[-11:, 0:11] = 255\n",
    "    mask_buf[0:1, :] = 255\n",
    "    mask_buf[-1:, :] = 255\n",
    "    mask_buf[:, 0:1] = 255\n",
    "    mask_buf[:, -1:] = 255\n",
    "    mask_buf = pcv.fill(bin_img=mask_buf, size=size_fill)\n",
    "    img_modified = np.ones_like(img) * 255\n",
    "    img_modified[mask_buf == 0] = img[mask_buf == 0]\n",
    "    return img_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImgDataSet(path):\n",
    "    img_path_list = [\n",
    "         [[foldername, fn, '/'.join(\n",
    "              [e for e in foldername.split(\"/\") if e not in [\"..\", \".\"]])]\n",
    "          for fn in filenames]\n",
    "         for foldername, subdirectory, filenames in os.walk(path)\n",
    "         if len(filenames)]\n",
    "    img_path_list = np.array([element for sous_liste in\n",
    "                              img_path_list for element in sous_liste])\n",
    "    img_array = np.array(\n",
    "         [np.array(Image.open(str(img_path[0] + \"/\" + img_path[1]), \"r\"))\n",
    "          for img_path in img_path_list])\n",
    "    img_back_removed = [removeBack(img, 5000, 1, 10) for img in img_array]\n",
    "    img_back_removed_IMG = [Image.fromarray(img_array)\n",
    "                            for img_array in img_back_removed]\n",
    "    [os.makedirs(\"increased/\" + path[2], exist_ok=True)\n",
    "     for path in img_path_list]\n",
    "    [img.save(\"increased/\" + path[2] + \"/\" + path[1])\n",
    "     for path, img in zip(img_path_list, img_back_removed_IMG)]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partition_tf(ds, train_split=0.85,\n",
    "                             shuffle=True, shuffle_size=10000):\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size, seed=12)\n",
    "    len_train_dataset = int(len(ds) * train_split)\n",
    "    train_dataset = ds.take(len_train_dataset)\n",
    "    cv_dataset = ds.skip(len_train_dataset)\n",
    "    return train_dataset, cv_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 15\n",
    "path = \"increased\"\n",
    "save_dir = \"\"\n",
    "save_name = \"learnings\"\n",
    "img_size = 256\n",
    "input_shape = (img_size, img_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12175 files belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = loadDataset(\"../increased/leaves/images\", img_size, batch_size)\n",
    "train_ds, validation_ds = get_dataset_partition_tf(dataset)\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(\n",
    "    buffer_size=tf.data.AUTOTUNE)\n",
    "validation_ds = validation_ds.cache().shuffle(1000).prefetch(\n",
    "    buffer_size=tf.data.AUTOTUNE)\n",
    "class_names = dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(32, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(len(class_names), activation='softmax')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=input_shape)\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=False),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "323/323 [==============================] - ETA: 0s - loss: 1.3721 - accuracy: 0.5587"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    batch_size = 32,\n",
    "    verbose=1,\n",
    "    validation_data=validation_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
